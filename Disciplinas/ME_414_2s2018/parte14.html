<!DOCTYPE html>
<html>
<head>
  <title>ME414 - Estatística para Experimentalistas</title>

  <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <meta name="generator" content="pandoc" />




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">

  <base target="_blank">

  <script type="text/javascript">
    var SLIDE_CONFIG = {
      // Slide settings
      settings: {
                title: 'ME414 - Estatística para Experimentalistas',
                        subtitle: 'Parte 14',
                useBuilds: true,
        usePrettify: true,
        enableSlideAreas: true,
        enableTouch: true,
                        favIcon: '../logo-imecc.png',
              },

      // Author information
      presenters: [
            ]
    };
  </script>

  <link href="parte14_files/ioslides-13.5.1/fonts/fonts.css" rel="stylesheet" />
  <link href="parte14_files/ioslides-13.5.1/theme/css/default.css" rel="stylesheet" />
  <link href="parte14_files/ioslides-13.5.1/theme/css/phone.css" rel="stylesheet" />
  <script src="parte14_files/ioslides-13.5.1/js/modernizr.custom.45394.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/prettify/prettify.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/prettify/lang-r.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/prettify/lang-yaml.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/hammer.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/slide-controller.js"></script>
  <script src="parte14_files/ioslides-13.5.1/js/slide-deck.js"></script>

  <style type="text/css">

    b, strong {
      font-weight: bold;
    }

    em {
      font-style: italic;
    }

    slides > slide {
      -webkit-transition: all 0.4s ease-in-out;
      -moz-transition: all 0.4s ease-in-out;
      -o-transition: all 0.4s ease-in-out;
      transition: all 0.4s ease-in-out;
    }

    .auto-fadein {
      -webkit-transition: opacity 0.6s ease-in;
      -webkit-transition-delay: 0.4s;
      -moz-transition: opacity 0.6s ease-in 0.4s;
      -o-transition: opacity 0.6s ease-in 0.4s;
      transition: opacity 0.6s ease-in 0.4s;
      opacity: 0;
    }

    slides > slide:not(.nobackground):before {
      font-size: 12pt;
      content: "";
      position: absolute;
      bottom: 20px;
      left: 60px;
      background: url(../logo-imecc.png) no-repeat 0 50%;
      -webkit-background-size: 30px 30px;
      -moz-background-size: 30px 30px;
      -o-background-size: 30px 30px;
      background-size: 30px 30px;
      padding-left: 40px;
      height: 30px;
      line-height: 1.9;
    }
  </style>


</head>

<body style="opacity: 0">

<slides class="layout-widescreen">

  <slide class="title-slide segue nobackground">
        <aside class="gdbar"><img src="/Users/imac/Dropbox/Me414-offline-slides/logo-imecc.png"></aside>
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
    <hgroup class="auto-fadein">
      <h1 data-config-title><!-- populated from slide_config.json --></h1>
      <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
      <p data-config-presenter><!-- populated from slide_config.json --></p>
          </hgroup>
  </slide>

<slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Fundamentos de Inferência</h2></hgroup><article  id="fundamentos-de-inferencia">

</article></slide><slide class=''><hgroup><h2>Introdução</h2></hgroup><article  id="introducao" class="build">

<blockquote>
<p>Um dos principais objetivos da Estatística é tirar conclusões a partir dos dados.</p>
</blockquote>

<blockquote>
<p>Dados em geral consistem de uma amostra de elementos de uma população de interesse.</p>
</blockquote>

<blockquote>
<p>O objetivo é usar a amostra e tirar conclusões sobre a população.</p>
</blockquote>

<blockquote>
<p>Quão confiável será utilizar a informação obtida apenas de uma amostra para concluir algo sobre a população?</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Inferência Estatística</h2></hgroup><article  id="inferencia-estatistica" class="build">

<center>

<img src="figuras/inferencia.PNG" width=600>

</center>

<p><strong>Variável Aleatória</strong>: Característica numérica do resultado de um experimento.</p>

<p><strong>População</strong>: todos os elementos ou resultados de um problema que está sendo estudado.</p>

<p><strong>Amostra:</strong> qualquer subconjunto da população que contém os elementos que podem ser observados e é onde as quantidades de interesse podem ser medidas.</p>

</article></slide><slide class=''><hgroup><h2>Inferência Estatística</h2></hgroup><article  id="inferencia-estatistica-1" class="build">

<center>

<img src="figuras/inferencia.PNG" width=600>

</center>

<p><strong>Parâmetros</strong>: Característica numérica (desconhecida) da distribuição dos elementos da população.</p>

<p><strong>Estimador/Estatística</strong>: Função da amostra, construída com a finalidade de representar, ou estimar um parâmetro de interesse na população.</p>

<p><strong>Estimativa</strong>: Valor numérico que um estimador assume para uma dada amostra.</p>

</article></slide><slide class=''><hgroup><h2>Estatística</h2></hgroup><article  id="estatistica" class="build">

<ul class = 'build'>
<li>Seja \(X_{1},...,X_{n}\) uma amostra, \(T=f(X_{1},...,X_{n})\) é uma estatística.</li>
</ul>

<ul class = 'build'>
<li>\(\bar{X}_{n}=\frac{1}{n}\sum_{i=1}^{n}X_{i}=\frac{1}{n}(X_{1}+...+X_{n})\): a média amostral é uma estatística.</li>
</ul>

<ul class = 'build'>
<li>\(X_{(1)}=min\{X_{1},...,X_{n}\}\).</li>
</ul>

<ul class = 'build'>
<li>\(X_{(n)}=max\{X_{1},...,X_{n}\}\).</li>
</ul>

<ul class = 'build'>
<li>\(X_{(i)}\) é o i-ésimo valor da amostra ordenada.</li>
</ul>

<ul class = 'build'>
<li>Note que uma estatística é uma função que em uma determinada amostra assume um valor específico (estimativa).</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Estatística</h2></hgroup><article  id="estatistica-1" class="build">

<ul>
<li><p>Para que serve uma estatística? Para &quot;estimar&quot; os valores de uma distribuição, ou características de uma população.</p></li>
<li><p><strong>População:</strong></p>

<ul>
<li>\(\mbox{média}_{P}\).</li>
<li>\(\mbox{variância}_{P}\).</li>
</ul></li>
<li><p><strong>Amostra:</strong></p>

<ul>
<li>\(\mbox{média}_{A} = \sum_{i=1}^{n}\frac{X_{i}}{n}\) &quot;estima&quot; a \(\mbox{média}_{P}\).</li>
<li>\(\mbox{variância}_{A} = \sum_{i=1}^{n}\frac{(X_{i}-\mbox{média}_{A})^{2}}{n}\) &quot;estima&quot; a \(\mbox{variância}_{P}\)</li>
</ul></li>
</ul>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo" class="build">

<p>Temos interesse em conhecer a média e variância das alturas dos brasileiros adultos. Sabemos que a distribuição das alturas pode ser representada por um modelo normal.</p>

<blockquote>
<p>Solução 1: Medir a altura de todos os brasileiros adultos.</p>
</blockquote>

<blockquote>
<p>Solução 2: Selecionar de forma aleatória algumas pessoas (amostra), analisá-las e inferir propriedades para toda a população.</p>
</blockquote>

<center>

<img src="figuras/inferencia2.PNG" width=550>

</center>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-1" class="build">

<p>Seja \(\theta\) a proporção de alunos na Unicamp que concorda com a presença da PM no campus.</p>

<ul class = 'build'>
<li>Inviável perguntar para todos os estudantes: coleta-se uma amostra.</li>
</ul>

<ul class = 'build'>
<li>Planejamento amostral: obter uma amostra aleatória simples de tamanho \(n=100\) alunos, sem reposição.</li>
</ul>

<ul class = 'build'>
<li>cada \(X_{i}\), \(i=1,...,100\), vai assumir o valor 1 se o aluno \(i\) concorda com presença da PM, e 0 se não.</li>
</ul>

<ul class = 'build'>
<li>estatística: \(T=\frac{X_{1}+...+X_{100}}{100}\).</li>
</ul>

<ul class = 'build'>
<li>uma vez que a coleta foi implementada, \(T\) assume um valor, por exemplo, 0.63, que será usado para estimar \(\theta\), ou seja, \(\hat\theta=0.63\).</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Parâmetro</h2></hgroup><article  id="parametro" class="build">

<ul class = 'build'>
<li>Cada quantidade de interesse (como \(\theta\) no exemplo anterior) é chamada de parâmetro da população.</li>
</ul>

<ul class = 'build'>
<li>Para apresentar uma estimativa de um parâmetro (\(\hat\theta\)), devemos escolher uma estatística (\(T\)).</li>
</ul>

<ul class = 'build'>
<li>Note que da maneira que o plano amostral foi executado (amostra aleatória simples), a estatística \(T\) é uma variável aleatória, visto que cada vez que executarmos o plano amostral poderemos obter resultados diversos.</li>
</ul>

<ul class = 'build'>
<li>Portanto, a estatística \(T\) possui uma distribuição de probabilidade, chamada de <strong>distribuição amostral</strong> de T.</li>
</ul>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Distribuição Amostral</h2></hgroup><article  id="distribuicao-amostral">

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-2" class="build">

<p>Imagine um fenômeno de interesse que possa ser representado por uma v.a. \(X\) que assume os valores \(1\) ou \(2\) com igual probabilidade.</p>

<blockquote>
<p>\[
\begin{aligned}
\mu=E(X) &amp;= 1 \times P(X=1) +2 \times P(X=2) \\ 
&amp;= 1\times \frac{1}{2} + 2\times \frac{1}{2}=\frac{3}{2}
\end{aligned}
\]</p>
</blockquote>

<blockquote>
<p>\[
\begin{aligned}
\sigma^2&amp; =Var(X)= E[(X-\mu)^2]\\
&amp;= (1-1.5)^2 \times P(X=1) + (2-1.5)^2 \times P(X=2)\\
&amp; =\frac{1}{4}
\end{aligned}
\]</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-3" class="build">

<p>Imagine que uma população de interesse tenha distribuição como a de \(X\) definida anteriormente.</p>

<blockquote>
<p>Imagine também que, embora saibamos que os valores possíveis sejam \(1\) e \(2\), não tenhamos conhecimento sobre suas respectivas probabilidades.</p>
</blockquote>

<blockquote>
<p>Isto é, se temos \(N\) elementos nessa população, podemos pensar que a característica de interesse de cada elemento \(i\) segue uma v.a. \(X_i\) em que \(P(X_i=1)=P(X_i=2)=1/2\), mas nós não sabemos disso.</p>
</blockquote>

<blockquote>
<p>Imagine que o interesse seja \(\mu\).</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-4" class="build">

<p>Vamos coletar uma amostra aleatória simples com reposição (\(AAS_c\)) de tamanho \(n=2\) e calcular a média amostral.</p>

<blockquote>
<p>Usaremos esta média amostral para estimar \(\mu\).</p>
</blockquote>

<blockquote>
<p>Quão útil é esta estimativa que se baseia em apenas 2 elementos da população?</p>
</blockquote>

<blockquote>
<p>Quão precisa?</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-5" class="build">

<blockquote>
<p>Imagine que o aluno \(A\) coleta uma \(AAS_c\) com \(n=2\) a partir da população, obtém os dados e calcula \(\bar{x}\).</p>
</blockquote>

<blockquote>
<p>O aluno \(B\) coleta uma \(AAS_c\) com \(n=2\) a partir da população, obtém os dados e calcula \(\bar{x}\).</p>
</blockquote>

<blockquote>
<p>As duas médias amostrais serão necessariamente iguais?</p>
</blockquote>

<blockquote>
<p>A média amostral é uma v.a. e, portanto, tem uma distribuição de probabilidade.</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-6" class="build smaller">

<blockquote>
<p>Todas as combinações possíveis de valores para o primeiro e para o segundo elemento amostrados segundo o plano \(AAS_c\) com \(n=2\) são:</p>
</blockquote>

<table class = 'rmdtable'>
<tr class="header">
<th align="left">Possibilidades</th>
<th align="left">\((X_1=1,X_2=1)\)</th>
<th align="left">\((X_1=1,X_2=2)\)</th>
<th align="left">\((X_1=2,X_2=1)\)</th>
<th align="left">\((X_1=2,X_2=2)\)</th>
</tr>
<tr class="odd">
<td align="left">\(\bar{x}\)</td>
<td align="left">1</td>
<td align="left">1.5</td>
<td align="left">1.5</td>
<td align="left">2</td>
</tr>
<tr class="even">
<td align="left">\(P(X_1=i,X_2=j)\)</td>
<td align="left">0.25</td>
<td align="left">0.25</td>
<td align="left">0.25</td>
<td align="left">0.25</td>
</tr>
</table>

<blockquote>
<p>\[E(\bar{X})=1\times \frac{1}{4} + 1.5 \times \frac{1}{2} + 2\times \frac{1}{4}=\frac{3}{2}\]</p>
</blockquote>

<blockquote>
<p>\[
\begin{aligned}
Var(\bar{X})&amp;= E\left[(\bar{X}-E(\bar{X}))^2\right]\\
&amp;=(1-1.5)^2\times \frac{1}{4} + (1.5-1.5)^2\frac{1}{2} + (2-1.5)^2\frac{1}{4}=\frac{1}{8}
\end{aligned}
\]</p>
</blockquote>

<blockquote>
<p>Repare que: \(E(\bar{X})=\mu=E(X)\) e \(Var(\bar{X})=\frac{\sigma^2}{n}=\frac{Var(X)}{n}\).</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-7">

<p>Distribuição de probabilidade de \(X\) (esquerda) e de \(\bar{X}\) (direita):</p>

<center>

<img src="figuras/X_Xbar.png" width=500>

</center>

</article></slide><slide class=''><hgroup><h2>Distribuição Amostral</h2></hgroup><article  id="distribuicao-amostral-1" class="build">

<p><strong>Resultado:</strong></p>

<ul class = 'build'>
<li>Seja \(X\) uma v.a. com média \(\mu\) e variância \(\sigma^{2}\).</li>
</ul>

<ul class = 'build'>
<li>Seja \(X_{1},...,X_{n}\) uma amostra aleatória simples de \(X\).</li>
</ul>

<ul class = 'build'>
<li>\(\bar{X}_{n}=\frac{X_{1}+...+X_{n}}{n}\).</li>
</ul>

<ul class = 'build'>
<li>\(E\left(\bar{X}_{n}\right)=\mu\).</li>
</ul>

<ul class = 'build'>
<li>\(Var\left(\bar{X}_{n}\right)=\frac{\sigma^{2}}{n}\).</li>
</ul>

<blockquote>
<p>Ou seja, embora \(\mu\) seja desconhecido, sabemos que o valor esperado da média amostral é \(\mu\). Além disso, conforme o tamanho amostral aumenta, a imprecisão da média amostral para estimar \(\mu\) fica cada vez menor, pois \(Var(\bar{X})=\sigma^2/n\).</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-8">

<ul class = 'build'>
<li>Exemplo: \(X_{1},X_{2},X_{3}\) ensaios de Bernoulli(p) independentes.</li>
</ul>

<ul class = 'build'>
<li>\(\mu=E\left(X_{i}\right)=0.3 \hspace{0.2cm} \Rightarrow \hspace{0.2cm} E\left(\bar{X}_{3}\right)=0.3\).</li>
</ul>

<ul class = 'build'>
<li>\(\sigma^2=Var\left(X_{i}\right)=p(1-p)=0.3(0.7)=0.21 \hspace{0.2cm} \Rightarrow \hspace{0.2cm} Var\left(\bar{X}_{3}\right)=\frac{0.21}{3}=0.07\)</li>
</ul>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Teorema do Limite Central</h2></hgroup><article  id="teorema-do-limite-central">

</article></slide><slide class=''><hgroup><h2>Teorema do Limite Central</h2></hgroup><article  id="teorema-do-limite-central-1" class="build">

<p>Usando o resultado enunciado anteriormente, temos a esperança e a variância da média amostral \(\bar{X}\): \(E(\bar{X})=\mu\) e \(Var(\bar{X})=\frac{\sigma^2}{n}\).</p>

<blockquote>
<p>No entanto, para conhecermos a distribuição de probabilidade de \(\bar{X}\), como foi feito no exemplo anterior, é preciso conhecer todos os valores possíveis de \(X\) e suas respectivas probabilidades.</p>
</blockquote>

<blockquote>
<p>Mas, se conhecermos tudo isso, não precisamos fazer amostragem nem inferência: saberemos tudo o que desejarmos daquela população!</p>
</blockquote>

<blockquote>
<p>O exemplo anterior foi um caso hipotético apenas para demonstrar como a média amostral \(\bar{X}\) se comporta quando realizamos a amostragem.</p>
</blockquote>

<blockquote>
<p>Na prática, não teremos informações suficientes para de fato descrevermos a distribuição exata de \(\bar{X}\).</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Teorema Central do Limite (TLC)</h2></hgroup><article  id="teorema-central-do-limite-tlc" class="build">

<p><strong>Resultado</strong></p>

<p>Para uma amostra aleatória simples \(X_{1},...,X_{n}\) coletada de uma população com média \(\mu\) e variância \(\sigma^{2}\), a distribuição amostral de \(\bar{X}_{n}\) aproxima-se de uma <strong>distribuição Normal</strong> de média \(\mu\) e variância \(\frac{\sigma^{2}}{n}\), quando \(n\) for suficientemente grande.</p>

<blockquote>

</blockquote>

<p>Definimos também:</p>

<p>\[Z=\frac{\bar{X}_{n}-\mu}{\sigma / \sqrt{n}} \sim N(0,1)\]</p>

</article></slide><slide class=''><hgroup><h2>Teorema do Limite Central</h2></hgroup><article  id="teorema-do-limite-central-2">

<center>

<img src="figuras/TCL.png" width=750>

</center>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-9" class="build">

<p>Seja \(X_{1},...,X_{n}\) uma amostra aleatória de tamanho \(n\) tal que \(X\sim Exp(2)\): \[f_{X_{i}}(x)=2e^{-2x}, \qquad \mbox{para } x \geq 0\]</p>

<p>Então \(E\left(X_{i}\right)=\frac{1}{2}\) e \(Var\left(X_{i}\right)=\frac{1}{4}\).</p>

<p>Suponha que \(X_{i}\) modela o tempo de vida de um transistor em horas. Os tempos de vida de 100 transistores são coletados. Desejamos estudar a variável aleatória \(\bar{X}_{100}\) (média amostral de uma amostra de tamanho 100). Sabemos: \[E\left(\bar{X}_{100}\right)=\frac{1}{2} \qquad \mbox{e} \qquad Var\left(\bar{X}_{100}\right)=\frac{1/4}{100}=\frac{1}{400}.\]</p>

<p>Pelo TLC, temos que: \(\displaystyle \bar{X}_{n}\sim N\left(\frac{1}{2},\frac{1}{400}\right)\)</p>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-10">

<p>\[
\begin{aligned}
F_{\bar X_{100}}(x) = P\left(\bar{X}_{100} \leq x\right) &amp; = P\left(\frac{\bar{X}_{100}-(1/2)}{(1/2)/\sqrt{100}} \leq \frac{x-(1/2)}{(1/2)/\sqrt{100}}\right)  \\
&amp; = P\left(Z \leq 10(2x-1) \right) 
\end{aligned}
\]</p>

<p>e</p>

<p>\[
\begin{aligned}
P\left(\bar{X}_{100} \geq x\right) &amp; = 1 - P\left(\bar{X}_{100} &lt; x\right)  \\
 &amp; = 1 - P\left(\frac{\bar{X}_{100}-(1/2)}{(1/2)/\sqrt{100}} \leq \frac{x-(1/2)}{(1/2)/\sqrt{100}}\right)  \\
&amp; = 1 - P\left(Z \leq 10(2x-1) \right) 
\end{aligned}
\]</p>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-11" class="build">

<p>\(X=\) resultado obtido no lançamento de um dado honesto.</p>

<table class = 'rmdtable'>
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<tr class="header">
<th align="left">\(x\)</th>
<th align="left">1</th>
<th align="left">2</th>
<th align="left">3</th>
<th align="left">4</th>
<th align="left">5</th>
<th align="left">6</th>
</tr>
<tr class="odd">
<td align="left">\(p(x)=P(X=x)\)</td>
<td align="left">\(\frac{1}{6}\)</td>
<td align="left">\(\frac{1}{6}\)</td>
<td align="left">\(\frac{1}{6}\)</td>
<td align="left">\(\frac{1}{6}\)</td>
<td align="left">\(\frac{1}{6}\)</td>
<td align="left">\(\frac{1}{6}\)</td>
</tr>
</table>

<blockquote>
<p>\(E(X)=\frac{1}{6}\times(1+2+3+4+5+6)=\frac{21}{6}=3.5\)</p>
</blockquote>

<blockquote>
<p>\(Var(X)=\frac{1}{6}[(1+4+9+16+25+36)-\frac{1}{6}\times(21)^{2}]=\frac{35}{2}=17.5\)</p>
</blockquote>

<ul class = 'build'>
<li>\(X_i\): resultado do \(i\)-ésimo lançamento de um dado honesto.</li>
</ul>

<ul class = 'build'>
<li>\(X_i\) tem distribuição uniforme discreta \(\forall i\).</li>
</ul>

<ul class = 'build'>
<li>\(\mu=E(X_i)=3.5 \qquad\) e \(\qquad \sigma^2=Var(X_i)=17.5\), \(\forall i\).</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-12" class="build smaller">

<blockquote>
<p>Se temos uma amostra aleatória simples de tamanho \(n\): \(X_1,X_2,\ldots, X_n\), pelo TLC sabemos que a distribuição amostral de \(\bar{X}_n\) é aproximadamente Normal\(\left( 3.5, \frac{17.5}{n} \right)\).</p>
</blockquote>

<blockquote>
<p>O primeiro histograma a seguir mostra o resultado de 10000 repetições do seguinte experimento: observar o resultado do lançamento de 1 dado. Repare que é muito próximo de uma distribuição uniforme discreta (chance 1/6 para cada resultado).</p>
</blockquote>

<blockquote>
<p>O segundo histograma mostra o resultado de 10000 repetições do seguinte experimento: observar a média do lançamento de 2 dados (equivalente a observar a média de 2 lançamentos de um dado).</p>
</blockquote>

<blockquote>
<p>O último histograma mostra o resultado de 10000 repetições do seguinte experimento: observar a média do lançamento de 100 dados (equivalente a observar a média de 100 lançamentos de um dado).</p>
</blockquote>

<blockquote>
<p>Repare que conforme o número de dados (tamanho amostral) aumenta, a distribuição da média amostral se aproxima da distribuição normal com média 3.5 e variância cada vez menor (17.5/n).</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-13">

<center>

<img src="parte14_files/figure-html/unnamed-chunk-1-1.png" width="960" />

</center>

</article></slide><slide class=''><hgroup><h2>Teorema do Limite Central (TLC)</h2></hgroup><article  id="teorema-do-limite-central-tlc">

<p>Você pode verificar o comportamento de \(\bar{X}\) para vários tipos de distribuição de \(X\):</p>

<p><a href='https://nishantsbi.shinyapps.io/CLT_Shiny' title=''>https://nishantsbi.shinyapps.io/CLT_Shiny</a></p>

<p><a href='https://gallery.shinyapps.io/CLT_mean/' title=''>https://gallery.shinyapps.io/CLT_mean/</a></p>

</article></slide><slide class='segue dark nobackground level1'><hgroup class = 'auto-fadein'><h2>Aproximação da Distribuição Binomial pela Normal</h2></hgroup><article  id="aproximacao-da-distribuicao-binomial-pela-normal">

</article></slide><slide class=''><hgroup><h2>Aproximação da Binomial pela Normal</h2></hgroup><article  id="aproximacao-da-binomial-pela-normal" class="build">

<ul class = 'build'>
<li>Consideremos uma população em que a proporção de indivíduos portadores de uma certa característica seja \(p\). \[ X_{i} = \left\{
\begin{array}{ll}
1, &amp; \mbox{se o indivíduo i possui a característica} \\
0, &amp; \mbox{caso contrário} \\
\end{array}
\right.\]</li>
</ul>

<ul class = 'build'>
<li>\(\Rightarrow\) \(X_{i}\sim Bernoulli(p)\); \(i=1,2,...,n\).</li>
</ul>

<ul class = 'build'>
<li>Se as observações são independentes: \(S_{n}=X_{1}+...+X_{n}\sim Bin(n,p)\).</li>
</ul>

<ul class = 'build'>
<li>Após a coleta de uma amostra aleatória simples de \(n\) indivíduos, podemos considerar:</li>
</ul>

<ul class = 'build'>
<li>\(\hat{p}=\frac{S_{n}}{n}\) (média amostral como estimador da média populacional).</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Aproximação da Binomial pela Normal</h2></hgroup><article  id="aproximacao-da-binomial-pela-normal-1" class="build">

<p>Utilizando a distribuição exata (n pequeno): \[P\left(\hat{p}=\frac{k}{n}\right)=P\left(\frac{S_{n}}{n}=\frac{k}{n}\right)=P\left(S_{n}=k\right)=\left(\begin{array}{l}
n \\
k \\
\end{array}\right)p^{k}\left(1-p\right)^{n-k},\]<br/>para \(k=0,1,...,n\).</p>

<blockquote>
<p>Utilizando a aproximação para a Normal (n grande): \[\hat{p}\sim N\left(p,\frac{p(1-p)}{n}\right)\]</p>
</blockquote>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-14" class="build">

<p>Se \(p\) for a proporção de fumantes no estado de SP, \(p=0.2\) e tivermos coletado uma amostra aleatória simples de 500 indivíduos: \[ X_{i} = \left\{
\begin{array}{ll}
1, &amp; \mbox{se o indivíduo i é fumante} \\
0, &amp; \mbox{caso contrário} \\
\end{array}
\right.\]</p>

<ul class = 'build'>
<li>\(\hat{p}=\frac{\sum_{i=1}^{500}X_{i}}{500}\).</li>
</ul>

<ul class = 'build'>
<li>\(\hat{p}\sim N\left(0.2,\frac{0.2\times0.8}{500}\right)=N\left(0.2,0.00032\right)\)</li>
</ul>

<ul class = 'build'>
<li>\(P\left(\hat{p}\leq 0.25\right)= P\left(Z\leq 2.795\right)=\Phi\left(2.795\right)=0.9974\)</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Aproximação da Binomial pela Normal</h2></hgroup><article  id="aproximacao-da-binomial-pela-normal-2" class="build">

<ul class = 'build'>
<li>\(\hat{p}=\frac{S_{n}}{n}\) \(\Rightarrow\) \(S_{n}=n\hat{p}\).</li>
</ul>

<ul class = 'build'>
<li>Quando \(n\) é grande o suficiente \(\hat{p}\sim N\left(p,\frac{p(1-p)}{n}\right)\).</li>
</ul>

<ul class = 'build'>
<li>Qual a distribuição de \(S_{n}\) quando n é grande o suficiente?</li>
</ul>

<ul class = 'build'>
<li>\(S_{n}=X_{1}+...+X_{n}\)</li>
</ul>

<ul class = 'build'>
<li>\(\hat{p}=\frac{S_{n}}{n} \sim N\left(p,\frac{p(1-p)}{n}\right)\)</li>
</ul>

<ul class = 'build'>
<li>\(S_{n}=n\hat{p}\sim N\left(np,np(1-p)\right)\)</li>
</ul>

<ul class = 'build'>
<li>Portanto: \(Bin(n,p)\approx N\left(np,np(1-p)\right)\) quando \(n\) é grande</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Exemplo</h2></hgroup><article  id="exemplo-15" class="build">

<p>\(X\sim Bin(100,0.4)\)</p>

<ul class = 'build'>
<li>\(E(X)=100\times0.4=40\)</li>
</ul>

<ul class = 'build'>
<li>\(Var(X)=100\times0.4\times0.6=24\)</li>
</ul>

<ul class = 'build'>
<li>\(X \approx N(40,24)\)</li>
</ul>

<ul class = 'build'>
<li>\(P\left(X\leq 50\right)= P\left(Z\leq \frac{50-40}{\sqrt{24}}\right)\approx \Phi\left(\frac{10}{\sqrt{24}}\right)=\Phi\left(2.04\right)\approx0.9793\)</li>
</ul>

</article></slide><slide class=''><hgroup><h2>Leituras</h2></hgroup><article  id="leituras">

<ul>
<li><a href='http://www.sciencedirect.com/science/article/pii/B9780123743886000077' title=''>Ross</a>: capítulo 7.</li>
<li><a href='https://www.openintro.org/stat/textbook.php' title=''>OpenIntro</a>: seção 4.1.</li>
<li>Magalhães: capítulo 7.</li>
</ul>

</article></slide><slide class=''><hgroup><h2></h2></hgroup><article  id="section">

<p>Slides produzidos pelos professores:</p>

<ul>
<li><p>Samara Kiihl</p></li>
<li><p>Tatiana Benaglia</p></li>
<li><p>Benilton Carvalho</p></li>
</ul></article></slide>


  <slide class="backdrop"></slide>

</slides>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "parte14_files/mathjax-local/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!-- map slide visiblity events into shiny -->
<script>
  (function() {
    if (window.jQuery) {
       window.jQuery(document).on('slideleave', function(e) {
         window.jQuery(e.target).trigger('hidden');
      });
       window.jQuery(document).on('slideenter', function(e) {
         window.jQuery(e.target).trigger('shown');
      });
    }
  })();
</script>

</body>
</html>
